{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "In this notebook we will load a trained GMF++ model, and go over the evaluation procedure. The GMF++ is based on simple model introduced by [He et al](https://arxiv.org/abs/1708.05031). You can try to adapt other models such as MLP and NMF. The [original implementation](https://github.com/hexiangnan/neural_collaborative_filtering/tree/4aab159e81c44b062c091bdaed0ab54ac632371f) as well as other implemntations are available for single market settings.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "import json\n",
    "import resource\n",
    "import sys\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "\n",
    "sys.path.insert(1, 'src')\n",
    "from model import Model\n",
    "from utils import *\n",
    "from data import *\n",
    "from train_baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "parser = create_arg_parser()\n",
    "\n",
    "tgt_market = 't1' \n",
    "src_markets = 'none' # 'none' | 's1' | 's1_s2_s3'\n",
    "exp_names = 'toytest'\n",
    "tgt_market_valid = f'DATA/{tgt_market}/valid_run.tsv'\n",
    "tgt_market_test = f'DATA/{tgt_market}/test_run.tsv'\n",
    "mat_path = f'./baseline_outputs/mat_dir/{tgt_market}'\n",
    "\n",
    "args = parser.parse_args(f'--tgt_market {tgt_market} --src_markets {src_markets} \\\n",
    "            --tgt_market_valid {tgt_market_valid} --tgt_market_test {tgt_market_test} --cuda'.split()) #\n",
    "\n",
    "args.device = torch.device('cuda:2' if torch.cuda.is_available() and args.cuda else 'cpu')\n",
    "print(\"Device:\", args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is NGCF!\n",
      "NGCF(\n",
      "  (embedding_dict): ParameterDict(\n",
      "      (item_emb): Parameter containing: [torch.cuda.FloatTensor of size 1386x128 (GPU 2)]\n",
      "      (user_emb): Parameter containing: [torch.cuda.FloatTensor of size 2698x128 (GPU 2)]\n",
      "  )\n",
      "  (weight_dict): ParameterDict(\n",
      "      (W_gc_0): Parameter containing: [torch.cuda.FloatTensor of size 128x128 (GPU 2)]\n",
      "      (b_gc_0): Parameter containing: [torch.cuda.FloatTensor of size 1x128 (GPU 2)]\n",
      "      (W_bi_0): Parameter containing: [torch.cuda.FloatTensor of size 128x128 (GPU 2)]\n",
      "      (b_bi_0): Parameter containing: [torch.cuda.FloatTensor of size 1x128 (GPU 2)]\n",
      "      (W_gc_1): Parameter containing: [torch.cuda.FloatTensor of size 128x128 (GPU 2)]\n",
      "      (b_gc_1): Parameter containing: [torch.cuda.FloatTensor of size 1x128 (GPU 2)]\n",
      "      (W_bi_1): Parameter containing: [torch.cuda.FloatTensor of size 128x128 (GPU 2)]\n",
      "      (b_bi_1): Parameter containing: [torch.cuda.FloatTensor of size 1x128 (GPU 2)]\n",
      "      (W_gc_2): Parameter containing: [torch.cuda.FloatTensor of size 128x128 (GPU 2)]\n",
      "      (b_gc_2): Parameter containing: [torch.cuda.FloatTensor of size 1x128 (GPU 2)]\n",
      "      (W_bi_2): Parameter containing: [torch.cuda.FloatTensor of size 128x128 (GPU 2)]\n",
      "      (b_bi_2): Parameter containing: [torch.cuda.FloatTensor of size 1x128 (GPU 2)]\n",
      "  )\n",
      "  (linear): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      "  (gmf): GMF(\n",
      "    (affine_output): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "    (logistic): Sigmoid()\n",
      "  )\n",
      "  (mlp): MLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=32, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "    (logistic): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_toytest.model are loaded!\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model_dir = f'checkpoints/{tgt_market}_{src_markets}_{exp_names}.model'\n",
    "id_bank_dir = f'checkpoints/{tgt_market}_{src_markets}_{exp_names}.pickle'\n",
    "\n",
    "with open(id_bank_dir, 'rb') as centralid_file:\n",
    "    my_id_bank = pickle.load(centralid_file)\n",
    "\n",
    "norm_mat = sp.load_npz(mat_path + '/s_norm_adj_mat.npz')\n",
    "mymodel = Model(args, my_id_bank, norm_mat)\n",
    "mymodel.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ddf6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in mymodel.model.named_parameters():\n",
    "# \tprint(name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded target test and validation data!\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## Target Market Evaluation data\n",
    "############\n",
    "tgt_task_generator = TaskGenerator(None, my_id_bank)\n",
    "args.batch_size = 10240\n",
    "tgt_valid_dataloader = tgt_task_generator.instance_a_market_valid_dataloader(args.tgt_market_valid, args.batch_size)\n",
    "tgt_test_dataloader = tgt_task_generator.instance_a_market_valid_dataloader(args.tgt_market_test, args.batch_size)\n",
    "print('loaded target test and validation data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = './baseline_outputs/sample_run/'\n",
    "\n",
    "def initia_write_run_file(run_mf, file_address):\n",
    "    with open(file_address, 'w') as fo:\n",
    "        fo.write('userId\\titemId\\tscore\\n')\n",
    "        for u_id in run_mf:\n",
    "            for p_id in run_mf[u_id]:\n",
    "                fo.write('{}\\t{}\\t{}\\n'.format(u_id, p_id, run_mf[u_id][p_id]))\n",
    "\n",
    "# 优化前t1 5m, t2 22m\n",
    "# 优化后t1 6.3s, t2 26.7s\n",
    "valid_run_mf = mymodel.predict(tgt_valid_dataloader)\n",
    "test_run_mf = mymodel.predict(tgt_test_dataloader)\n",
    "\n",
    "valid_run_mf = conver_data(valid_run_mf, my_id_bank)\n",
    "test_run_mf = conver_data(test_run_mf, my_id_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_run_file(run_mf, file_address):\n",
    "    with open(file_address, 'w') as fo:\n",
    "        fo.write('userId\\titemId\\tscore\\n')\n",
    "        for row in run_mf.itertuples():\n",
    "            u_id = row.userId\n",
    "            for score, i_id in enumerate(row.user_sort_item):\n",
    "                fo.write('{}\\t{}\\t{}\\n'.format(u_id, i_id, (10-score)/10+2))  # 随便给个递减分数就行\n",
    "\n",
    "write_run_file(valid_run_mf, path.join(run_dir, tgt_market, 'valid_pred.tsv'))\n",
    "write_run_file(test_run_mf, path.join(run_dir, tgt_market, 'test_pred.tsv'))\n",
    "\n",
    "# get full evaluation on validation set using pytrec_eval.\n",
    "tgt_valid_qrel = read_qrel_file('DATA/{}/valid_qrel.tsv'.format(tgt_market))\n",
    "task_ov, task_ind = get_evaluations_final(valid_run_mf, tgt_valid_qrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: t1/ (stored 0%)\n",
      "updating: t1/test_pred.tsv (deflated 67%)\n",
      "updating: t1/valid_pred.tsv (deflated 67%)\n",
      "updating: t2/ (stored 0%)\n",
      "updating: t2/test_pred.tsv (deflated 67%)\n",
      "updating: t2/valid_pred.tsv (deflated 68%)\n",
      "*** Validating the submission Zip file ***\n",
      "Extracting the submission zip file\n",
      "Validating the file structure of the submission\n",
      "File structure validation successfully passed\n",
      "Evaluating the validation set\n",
      "===================== Market : t1=====================\n",
      "======= Set val : score(ndcg10_val)=0.685858735455 =======\n",
      "======= Set val : score(r10_val)=0.772339636633 =======\n",
      "===================== Market : t2=====================\n",
      "======= Set val : score(ndcg10_val)=0.596880971680 =======\n",
      "======= Set val : score(r10_val)=0.695549069683 =======\n",
      "===================== Market : t1t2=====================\n",
      "======= Set val : score(ndcg10_val)=0.626221114595 =======\n",
      "======= Set val : score(r10_val)=0.720870522069 =======\n"
     ]
    }
   ],
   "source": [
    "# Zip the run files into a single archive to prepare for submission  \n",
    "run_dir = './baseline_outputs/sample_run/'\n",
    "! cd {run_dir} && zip -r ../sample_run.zip ./\n",
    "\n",
    "print(\"*** Validating the submission Zip file ***\")\n",
    "# Run the validate_submission.py script to check if the file format is okay and get the performance on validation set.\n",
    "! python validate_submission.py ./baseline_outputs/sample_run.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
