{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t1 = pd.read_csv('DATA/t1/train.tsv', sep='\\t')\n",
    "train_5core_t1 = pd.read_csv('DATA/t1/train_5core.tsv', sep='\\t')\n",
    "valid_qrel_t1 = pd.read_csv('DATA/t1/valid_qrel.tsv', sep='\\t') # 验证集 正样本\n",
    "valid_run_t1 = pd.read_csv('DATA/t1/valid_run.tsv', sep='\\t', header=None) # 验证样本\n",
    "valid_run_t1.columns = ['userId','itemIds']\n",
    "test_run_t1 = pd.read_csv('DATA/t1/test_run.tsv', sep='\\t', header=None) # 测试样本\n",
    "test_run_t1.columns = ['userId','itemIds']\n",
    "\n",
    "train_t2 = pd.read_csv('DATA/t2/train.tsv', sep='\\t')\n",
    "train_5core_t2 = pd.read_csv('DATA/t2/train_5core.tsv', sep='\\t')\n",
    "valid_qrel_t2 = pd.read_csv('DATA/t2/valid_qrel.tsv', sep='\\t') # 验证集 正样本\n",
    "valid_run_t2 = pd.read_csv('DATA/t2/valid_run.tsv', sep='\\t', header=None) # 验证样本\n",
    "valid_run_t2.columns = ['userId','itemIds']\n",
    "test_run_t2 = pd.read_csv('DATA/t2/test_run.tsv', sep='\\t', header=None) # 测试样本\n",
    "test_run_t2.columns = ['userId','itemIds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def item_cf(df, user_col, item_col):  # train, 'itemId', 'userId'\n",
    "    user_item_ = df.groupby(user_col)[item_col].agg(list).reset_index()     # user的item列表\n",
    "    user_item_dict = dict(zip(user_item_[user_col], user_item_[item_col]))  # 变成字典\n",
    "    \n",
    "    sim_item = {}                                  # 里面存的又是字典\n",
    "    item_cnt = defaultdict(int)  \n",
    "    for user, items in tqdm(user_item_dict.items()):     # 这段逻辑是用户交互过的item之间的相似度为  1 / math.log(1 + len(items))\n",
    "        for item in items:                                                  \n",
    "            item_cnt[item] += 1                    # item出现的频次\n",
    "            sim_item.setdefault(item, {})          # 查找item键值，不存在设为空字典\n",
    "            for relate_item in items:  \n",
    "                if item == relate_item:            # item自身无相似度\n",
    "                    continue\n",
    "                \n",
    "                sim_item[item].setdefault(relate_item, 0)   # 如果不存在，先设为0\n",
    "                sim_item[item][relate_item] += 1 / math.log(1 + len(items))\n",
    "                \n",
    "    sim_item_corr = sim_item.copy()\n",
    "    for i, related_items in tqdm(sim_item.items()):     # 做个类似于归一化的计算\n",
    "        for j, cij in related_items.items():  \n",
    "            sim_item_corr[i][j] = cij / math.sqrt(item_cnt[i]*item_cnt[j])   # 相似度矩阵\n",
    "  \n",
    "    return sim_item_corr, user_item_dict\n",
    "\n",
    "\n",
    "def recommend(sim_item_corr, user_item_dict, user_id):  # 相似度矩阵, user交互的item列表, 用户id\n",
    "    rank = {}\n",
    "    try:\n",
    "        interacted_items = user_item_dict[user_id]      # 取出用户交互过的item\n",
    "    except:\n",
    "        interacted_items = {}\n",
    "    for i in interacted_items:\n",
    "        try:\n",
    "            for j, wij in sorted(sim_item_corr[i].items(), key=lambda d: d[1], reverse=True):  # 按照相似度进行排序\n",
    "                if j not in interacted_items:       # 没有交互过的item加入到待排序列中\n",
    "                    rank.setdefault(j, 0)\n",
    "                    rank[j] += wij                  \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return sorted(rank.items(), key=lambda d: d[1], reverse=True)   # 将相似度排序后返回\n",
    " \n",
    "\n",
    "def match_func(items1, items2):  # 所有候选项, run中的候选项\n",
    "    res = []\n",
    "    for it in items1:\n",
    "        if it in items2:\n",
    "            res.append(it)\n",
    "    if len(res) < 100:      # 如果不够100个，补齐，其实10个就完全够了\n",
    "        for it in items2:\n",
    "            if it not in res:\n",
    "                res.append(it)\n",
    "    return res[:100]\n",
    "    \n",
    "\n",
    "def recall_func(train, valid_run):\n",
    "    # 构建相似矩阵\n",
    "    item_sim_list, user_item = item_cf(train, 'userId', 'itemId')\n",
    "    \n",
    "    # 对每个user进行召回\n",
    "    recom_item = []\n",
    "    for i in tqdm(valid_run['userId'].unique()):\n",
    "        \n",
    "        rank_item = recommend(item_sim_list, user_item, i)\n",
    "        \n",
    "        for j in rank_item:  \n",
    "            if j[1] > 0.001:  # 相似度大于0.001才加入待排序列\n",
    "                recom_item.append([i, j[0], j[1]])  \n",
    "\n",
    "    ############## 转为DataFrame\n",
    "    recom_item_df = pd.DataFrame(recom_item)\n",
    "    recom_item_df.columns = ['userId','itemId','score']\n",
    "    \n",
    "    # 聚合itemId成list\n",
    "    recom_df = recom_item_df.groupby(['userId'])['itemId'].agg(list).reset_index()\n",
    "    recom_df.columns = ['userId','pred_itemIds']      # 所有的item候选项\n",
    "\n",
    "    # 合并验证集itemIds，只挑选run中有的item\n",
    "    recom_df = recom_df.merge(valid_run, on='userId', how='left')\n",
    "    recom_df['itemIds'] =  recom_df['itemIds'].apply(lambda x:x.split(','))\n",
    "    \n",
    "    recom_df['result_itemIds'] = recom_df.apply(lambda row:match_func(row['pred_itemIds'], row['itemIds']),axis = 1)  # 通过run筛选后的item候选项\n",
    "    \n",
    "    return recom_df\n",
    "\n",
    "\n",
    "# 热度填充,目前未使用到\n",
    "def hot_fill(train, valid_run, test_run):\n",
    "    \n",
    "    # 验证数据\n",
    "    valid_run = valid_run.merge(valid_recom_df, on='userId', how='left')\n",
    "\n",
    "    # 按热度进行填充\n",
    "    valid_run['hot_itemIds'] = ','.join(train['itemId'].value_counts().reset_index()['index'].tolist())  # 每一行都有热度itemIds\n",
    "    valid_run['itemIds'] = valid_run['itemIds'].apply(lambda x:x.split(','))\n",
    "    valid_run['hot_itemIds'] = valid_run['hot_itemIds'].apply(lambda x:x.split(','))\n",
    "    valid_run['hot_itemIds'] = valid_run.apply(lambda row:match_func(row['hot_itemIds'], row['itemIds']),axis = 1)\n",
    "    valid_run['hot_itemIds'] = valid_run['hot_itemIds'].apply(lambda x:','.join(x))\n",
    "    valid_run.loc[valid_run.result_itemIds.isnull(), 'result_itemIds'] = \\\n",
    "    valid_run.loc[valid_run.result_itemIds.isnull(), 'hot_itemIds']\n",
    "    \n",
    "    # 测试数据\n",
    "    test_run = test_run.merge(test_recom_df, on='userId', how='left')\n",
    "\n",
    "    # 按热度进行填充\n",
    "    test_run['hot_itemIds'] = ','.join(train['itemId'].value_counts().reset_index()['index'].tolist())\n",
    "    test_run['itemIds'] = test_run['itemIds'].apply(lambda x:x.split(','))\n",
    "    test_run['hot_itemIds'] = test_run['hot_itemIds'].apply(lambda x:x.split(','))\n",
    "    test_run['hot_itemIds'] = test_run.apply(lambda row:match_func(row['hot_itemIds'], row['itemIds']),axis = 1)\n",
    "    test_run['hot_itemIds'] = test_run['hot_itemIds'].apply(lambda x:','.join(x))\n",
    "    test_run.loc[test_run.result_itemIds.isnull(), 'result_itemIds'] = \\\n",
    "    test_run.loc[test_run.result_itemIds.isnull(), 'hot_itemIds']\n",
    "    \n",
    "    return valid_run, test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDCG(scores):\n",
    "    return np.sum(\n",
    "        np.divide(np.power(2, scores) - 1, np.log2(np.arange(scores.shape[0], dtype=np.float32) + 2)),\n",
    "        dtype=np.float32)\n",
    "\n",
    "def getNDCG(rank_list, pos_items):\n",
    "    relevance = np.ones_like(pos_items)\n",
    "    it2rel = {it: r for it, r in zip(pos_items, relevance)}\n",
    "    rank_scores = np.asarray([it2rel.get(it, 0.0) for it in rank_list], dtype=np.float32)\n",
    "\n",
    "    #idcg = getDCG(relevance)\n",
    "    idcg = 1\n",
    "    \n",
    "    dcg = getDCG(rank_scores)\n",
    "\n",
    "    if dcg == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = './baseline_outputs/sample_run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_recom_df......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9742/9742 [00:00<00:00, 23236.82it/s]\n",
      "100%|██████████| 3429/3429 [00:00<00:00, 32901.58it/s]\n",
      "100%|██████████| 2697/2697 [00:17<00:00, 154.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_recom_df......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9742/9742 [00:00<00:00, 14093.75it/s]\n",
      "100%|██████████| 3429/3429 [00:00<00:00, 16887.02it/s]\n",
      "100%|██████████| 2697/2697 [00:17<00:00, 158.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 NDCG :  0.5832278451567718\n"
     ]
    }
   ],
   "source": [
    "## t1结果\n",
    "print('valid_recom_df......')\n",
    "valid_recom_df = recall_func(train_t1, valid_run_t1)  # train_t1原始训练数据, valid_run_t1待排序数据\n",
    "print('test_recom_df......')\n",
    "test_recom_df = recall_func(train_t1, test_run_t1)    # train_t1原始训练数据, valid_run_t1待排序数据\n",
    "\n",
    "valid_qrel = valid_qrel_t1\n",
    "\n",
    "# 合并验证集真实结果\n",
    "valid_recom_df = valid_recom_df.merge(valid_qrel, on='userId', how='left')\n",
    "\n",
    "# 计算NDCG分数\n",
    "NDCG = 0\n",
    "for items in valid_recom_df[['result_itemIds','itemId']].values:\n",
    "    l1 = items[0][:10]\n",
    "    l2 = [items[1]]\n",
    "    NDCG += getNDCG(l1, l2)\n",
    "NDCG = NDCG/len(valid_run_t1)\n",
    "print('t1 NDCG : ', NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存t1结果，生成tsv文件\n",
    "# 验证集\n",
    "userId = []\n",
    "itemId = []\n",
    "for index, row in valid_recom_df[['userId', 'result_itemIds']].iterrows():\n",
    "    userId += [row.userId]*len(row.result_itemIds)\n",
    "    itemId += row.result_itemIds\n",
    "df = pd.DataFrame(columns=['userId','itemId','score'])\n",
    "df['userId'] = userId\n",
    "df['itemId'] = itemId\n",
    "df['score'] = [len(itemId)-i for i in range(len(itemId))]\n",
    "df.to_csv(run_dir+'t1/valid_pred.tsv', sep='\\t', index=False)\n",
    "# 测试集\n",
    "userId = []\n",
    "itemId = []\n",
    "for index, row in test_recom_df[['userId', 'result_itemIds']].iterrows():\n",
    "    userId += [row.userId]*len(row.result_itemIds)\n",
    "    itemId += row.result_itemIds\n",
    "df = pd.DataFrame(columns=['userId','itemId','score'])\n",
    "df['userId'] = userId\n",
    "df['itemId'] = itemId\n",
    "df['score'] = [len(itemId)-i for i in range(len(itemId))]\n",
    "df.to_csv(run_dir+'t1/test_pred.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_recom_df......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18242/18242 [00:01<00:00, 12492.80it/s]\n",
      "100%|██████████| 8834/8834 [00:00<00:00, 18689.40it/s]\n",
      "100%|██████████| 5482/5482 [01:00<00:00, 91.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_recom_df......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18242/18242 [00:01<00:00, 11709.49it/s]\n",
      "100%|██████████| 8834/8834 [00:00<00:00, 13168.67it/s]\n",
      "100%|██████████| 5482/5482 [01:04<00:00, 84.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2 NDCG :  0.5077369139712903\n"
     ]
    }
   ],
   "source": [
    "## t2结果\n",
    "print('valid_recom_df......')\n",
    "valid_recom_df = recall_func(train_t2, valid_run_t2)\n",
    "print('test_recom_df......')\n",
    "test_recom_df = recall_func(train_t2, test_run_t2)\n",
    "\n",
    "valid_qrel = valid_qrel_t2\n",
    "\n",
    "# 合并验证集真实结果\n",
    "valid_recom_df = valid_recom_df.merge(valid_qrel, on='userId', how='left')\n",
    "\n",
    "# 计算NDCG分数\n",
    "NDCG = 0\n",
    "for items in valid_recom_df[['result_itemIds','itemId']].values:\n",
    "    l1 = items[0][:10]                                               # 只取前10个item\n",
    "    l2 = [items[1]]\n",
    "    NDCG += getNDCG(l1, l2)\n",
    "NDCG = NDCG/len(valid_run_t2)\n",
    "print('t2 NDCG : ', NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存t2结果，生成tsv文件\n",
    "# 验证集\n",
    "userId = []\n",
    "itemId = []\n",
    "for index, row in valid_recom_df[['userId', 'result_itemIds']].iterrows():\n",
    "    userId += [row.userId]*len(row.result_itemIds)\n",
    "    itemId += row.result_itemIds\n",
    "df = pd.DataFrame(columns=['userId','itemId','score'])\n",
    "df['userId'] = userId\n",
    "df['itemId'] = itemId\n",
    "df['score'] = [len(itemId)-i for i in range(len(itemId))]\n",
    "df.to_csv(run_dir+'t2/valid_pred.tsv', sep='\\t', index=False)\n",
    "# 测试集\n",
    "userId = []\n",
    "itemId = []\n",
    "for index, row in test_recom_df[['userId', 'result_itemIds']].iterrows():\n",
    "    userId += [row.userId]*len(row.result_itemIds)\n",
    "    itemId += row.result_itemIds\n",
    "df = pd.DataFrame(columns=['userId','itemId','score'])\n",
    "df['userId'] = userId\n",
    "df['itemId'] = itemId\n",
    "df['score'] = [(len(itemId)-i)/len(itemId)+2 for i in range(len(itemId))]\n",
    "df.to_csv(run_dir+'t2/test_pred.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: t1/ (stored 0%)\n",
      "updating: t1/test_pred.tsv (deflated 76%)\n",
      "updating: t1/valid_pred.tsv (deflated 76%)\n",
      "updating: t2/ (stored 0%)\n",
      "updating: t2/test_pred.tsv (deflated 80%)\n",
      "updating: t2/valid_pred.tsv (deflated 76%)\n",
      "*** Validating the submission Zip file ***\n",
      "Extracting the submission zip file\n",
      "Validating the file structure of the submission\n",
      "File structure validation successfully passed\n",
      "Evaluating the validation set\n",
      "===================== Market : t1=====================\n",
      "======= Set val : score(ndcg10_val)=0.633238927193 =======\n",
      "======= Set val : score(r10_val)=0.726247987118 =======\n",
      "===================== Market : t2=====================\n",
      "======= Set val : score(ndcg10_val)=0.533221025908 =======\n",
      "======= Set val : score(r10_val)=0.629310344828 =======\n",
      "===================== Market : t1t2=====================\n",
      "======= Set val : score(ndcg10_val)=0.565469788472 =======\n",
      "======= Set val : score(r10_val)=0.660565939772 =======\n"
     ]
    }
   ],
   "source": [
    "# 压缩文件并验证结果\n",
    "! cd {run_dir} && zip -r ../sample_run.zip ./\n",
    "\n",
    "print(\"*** Validating the submission Zip file ***\")\n",
    "# Run the validate_submission.py script to check if the file format is okay and get the performance on validation set.\n",
    "! python validate_submission.py ./baseline_outputs/sample_run.zip"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b1e3767262450d72579892ea2b8405f0b39a1776e15a613db348d08410668c5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('xmrec': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
